[
["index.html", "Computational Stats 1 Lesson 1 1.1 Start by creating a vector 1.2 Now a Matrix! 1.3 DataFrames 1.4 Reading a Tab Separated File 1.5 Generating data 1.6 Getting insights 1.7 Lists 1.8 Functions", " Computational Stats Tiago dos Santos 2018-10-16 1 Lesson 1 x &lt;- 3+5 ls() ## [1] &quot;LatexOrOther&quot; &quot;datasetsDir&quot; &quot;fig_basePath&quot; &quot;x&quot; 1.1 Start by creating a vector y &lt;- c(2,5,9,8) y[1:3] ## [1] 2 5 9 y[c(1,3)] ## [1] 2 9 1.1.0.1 Get the elements 1,2,3 from the vector y[1:3] ## [1] 2 5 9 1.1.0.2 Get the elements 1,3 from the vector y[c(1,3)] ## [1] 2 9 1.1.0.3 Get an array from 0 to 1, with a 0.001 step y &lt;- 1:1000/1000 y &lt;- seq(0,1,0.001) 1.1.0.4 Which values are lower than 0.008? isValueLowerThan &lt;- y &lt; 0.008 y[isValueLowerThan] ## [1] 0.000 0.001 0.002 0.003 0.004 0.005 0.006 0.007 idxs &lt;- which(y&lt;0.08) y[idxs] ## [1] 0.000 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.010 ## [12] 0.011 0.012 0.013 0.014 0.015 0.016 0.017 0.018 0.019 0.020 0.021 ## [23] 0.022 0.023 0.024 0.025 0.026 0.027 0.028 0.029 0.030 0.031 0.032 ## [34] 0.033 0.034 0.035 0.036 0.037 0.038 0.039 0.040 0.041 0.042 0.043 ## [45] 0.044 0.045 0.046 0.047 0.048 0.049 0.050 0.051 0.052 0.053 0.054 ## [56] 0.055 0.056 0.057 0.058 0.059 0.060 0.061 0.062 0.063 0.064 0.065 ## [67] 0.066 0.067 0.068 0.069 0.070 0.071 0.072 0.073 0.074 0.075 0.076 ## [78] 0.077 0.078 0.079 1.1.0.5 Creating objects by repetition colors &lt;- c(&quot;amarelo&quot;,&quot;verde&quot;,&quot;vermelho&quot;,&quot;azul&quot;) rep(colors, 5) ## [1] &quot;amarelo&quot; &quot;verde&quot; &quot;vermelho&quot; &quot;azul&quot; &quot;amarelo&quot; &quot;verde&quot; ## [7] &quot;vermelho&quot; &quot;azul&quot; &quot;amarelo&quot; &quot;verde&quot; &quot;vermelho&quot; &quot;azul&quot; ## [13] &quot;amarelo&quot; &quot;verde&quot; &quot;vermelho&quot; &quot;azul&quot; &quot;amarelo&quot; &quot;verde&quot; ## [19] &quot;vermelho&quot; &quot;azul&quot; print(&quot;===&quot;) ## [1] &quot;===&quot; rep(10,5) ## [1] 10 10 10 10 10 1.2 Now a Matrix! M &lt;- matrix(1:9, ncol=3) M ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 Transposing the Matrix t(M) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 Accessing the Matrix M[1,2] ## [1] 4 M[1,] ## [1] 1 4 7 M[,2] ## [1] 4 5 6 Matrix Operation M2 &lt;- t(M) M+M2 # valuewise add ## [,1] [,2] [,3] ## [1,] 2 6 10 ## [2,] 6 10 14 ## [3,] 10 14 18 M*M2 # valuewise multiplication ## [,1] [,2] [,3] ## [1,] 1 8 21 ## [2,] 8 25 48 ## [3,] 21 48 81 M%*%M2 # Matricial Multiplication ## [,1] [,2] [,3] ## [1,] 66 78 90 ## [2,] 78 93 108 ## [3,] 90 108 126 1.2.0.1 Joining Matrixes Matrix Operation cbind(M,M2) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 4 7 1 2 3 ## [2,] 2 5 8 4 5 6 ## [3,] 3 6 9 7 8 9 rbind(M,M2) ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [4,] 1 2 3 ## [5,] 4 5 6 ## [6,] 7 8 9 1.2.0.2 Inverting a matrix #solve(M) # M must not be singular 1.3 DataFrames y &lt;- 1:10 y2 &lt;- 11:20 y3 &lt;- letters[1:10] d1 &lt;- data.frame(y,y2,y3) d1 ## y y2 y3 ## 1 1 11 a ## 2 2 12 b ## 3 3 13 c ## 4 4 14 d ## 5 5 15 e ## 6 6 16 f ## 7 7 17 g ## 8 8 18 h ## 9 9 19 i ## 10 10 20 j 1.4 Reading a Tab Separated File emp &lt;- read.table(file.path(datasetsDir,&quot;empresas.txt&quot;), header=F) knitr::kable(head(emp)) V1 V2 V3 V4 V5 Soflor 2 5 10 3 Florinha 3 10 22 7 Flora 5 30 55 18 Floflo 2 5 12 4 Fazflor 3 15 28 8 Comercflor 2 10 18 5 dim(emp) ## [1] 40 5 names(emp) &lt;- c(&quot;nome&quot;,&quot;n.socios&quot;,&quot;c.social&quot;,&quot;vmm&quot;,&quot;n.emp&quot;) knitr::kable(head(emp)) nome n.socios c.social vmm n.emp Soflor 2 5 10 3 Florinha 3 10 22 7 Flora 5 30 55 18 Floflo 2 5 12 4 Fazflor 3 15 28 8 Comercflor 2 10 18 5 emp$n.socios ## [1] 2 3 5 2 3 2 3 4 6 5 2 3 2 3 2 3 3 2 5 2 2 3 3 2 2 2 2 4 4 3 2 2 4 2 2 ## [36] 2 3 3 3 2 emp[,2] ## [1] 2 3 5 2 3 2 3 4 6 5 2 3 2 3 2 3 3 2 5 2 2 3 3 2 2 2 2 4 4 3 2 2 4 2 2 ## [36] 2 3 3 3 2 1.5 Generating data set.seed(5) emp$ant &lt;- round(rnorm(dim(emp)[1],10,1)) 1.6 Getting insights summary(emp) ## nome n.socios c.social vmm ## Alecrim : 1 Min. :2.00 Min. : 5.00 Min. : 5.00 ## Beijaflor : 1 1st Qu.:2.00 1st Qu.: 5.00 1st Qu.: 11.00 ## Caflor : 1 Median :3.00 Median :10.00 Median : 19.00 ## Comercflor: 1 Mean :2.85 Mean :11.72 Mean : 24.48 ## Cravinho : 1 3rd Qu.:3.00 3rd Qu.:15.00 3rd Qu.: 31.00 ## Cravo : 1 Max. :6.00 Max. :50.00 Max. :100.00 ## (Other) :34 ## n.emp ant ## Min. : 2.000 Min. : 8 ## 1st Qu.: 3.000 1st Qu.: 9 ## Median : 5.500 Median :10 ## Mean : 6.225 Mean :10 ## 3rd Qu.: 9.000 3rd Qu.:11 ## Max. :18.000 Max. :12 ## mean(emp$n.socios) ## [1] 2.85 sd(emp$n.socios) ## [1] 1.051251 tapply(emp$vmm, emp$n.emp, mean) # vmm mean by number of employes ## 2 3 4 5 6 7 ## 8.714286 10.875000 12.666667 18.000000 22.000000 23.000000 ## 8 9 10 11 14 15 ## 28.000000 32.250000 45.000000 61.000000 45.000000 100.000000 ## 16 18 ## 55.000000 55.000000 tapply(emp$vmm, emp$n.emp, sd) # vmm sd by number of employes ## 2 3 4 5 6 7 8 9 ## 2.627691 1.457738 1.154701 0.000000 1.414214 1.414214 NA 1.500000 ## 10 11 14 15 16 18 ## NA 1.414214 NA NA NA NA \\[ \\overline{X} = \\frac{1}{N}\\sum\\limits_{i=1}^{N}X_{i} \\] \\[\\begin{equation} \\label{eq:std} S^2 = \\frac{1}{N}\\sum\\limits_{i=1}^{N}(X_{i} - \\overline{X})^2 \\end{equation}\\] table(emp$n.emp) #first line are values, second line is frequency ## ## 2 3 4 5 6 7 8 9 10 11 14 15 16 18 ## 7 8 3 2 6 2 1 4 1 2 1 1 1 1 barplot(emp$n.emp) # each company is a bin in x label, y is the number of employees barplot(table(emp$n.emp), xlab=&quot;#Employees&quot;, ylab=&quot;Frequecy&quot;, col=&quot;pink&quot;) boxplot(emp$vmm,range=0,col=&quot;purple&quot;,horizontal=T,main=&quot;vmm&quot;) boxplot(emp$vmm ~ emp$n.emp,range=0,col=&quot;purple&quot;,horizontal=T,main=&quot;vmm&quot;) hist(emp$vmm) hist(emp$vmm, freq=F) lines(density(emp$vmm),col=2) par(mfrow=c(1,2)) hist(emp$vmm) hist(emp$vmm, freq=F) lines(density(emp$vmm),col=2) par(mfrow=c(1,1)) plot(emp$vmm,emp$n.socios,pch=16) plot(emp) 1.7 Lists uma.lista &lt;- list( um.vector=1:10, uma.palavra=&quot;olá&quot;, uma.matrix=M, outra.lista=list( a=&quot;flor&quot;, b=rep(3,5) ) ) uma.lista[&quot;um.vector&quot;] ## $um.vector ## [1] 1 2 3 4 5 6 7 8 9 10 uma.lista$um.vector ## [1] 1 2 3 4 5 6 7 8 9 10 uma.lista[1] ## $um.vector ## [1] 1 2 3 4 5 6 7 8 9 10 1.8 Functions desconto &lt;- function(price, discount=25){ #Discount is a number between 0 and 100 #calcula o desconto de um preço newPrice &lt;- price*(1-discount/100) discount &lt;- price - newPrice list( novo.preco=newPrice, desconto=discount) } desconto(1000,20) ## $novo.preco ## [1] 800 ## ## $desconto ## [1] 200 desconto(1000,25) ## $novo.preco ## [1] 750 ## ## $desconto ## [1] 250 This is how you function "],
["lessons-2.html", "2 Lessons 2 2.1 Random Variables and Vectors", " 2 Lessons 2 2.1 Random Variables and Vectors 2.1.1 Elements of probability A random variable \\(\\bold{X}\\) is a function that takes an event space and return a value: \\[ X: \\Omega \\rightarrow {\\rm I\\!R}\\] 2.1.2 Expected value "],
["lesson-3.html", "3 Lesson 3 3.1 Hypothesis Testing", " 3 Lesson 3 g &lt;- function(x){ exp(x^2) } #create sample from uniform distribution sample &lt;- runif(10000) sample.length &lt;- length(sample) mean(g(sample)) ## [1] 1.46525 3.0.1 Estimating pi g &lt;- function(x){ sqrt(1-x^2) } #create sample from uniform distribution sample &lt;- runif(100000000) mean(g(sample))*4 ## [1] 3.141693 gIndicatriz &lt;- function(x,y){ ifelse((x^2 + y^2) &lt;= 1, 1, 0) } sampleX &lt;- runif(1000000) sampleY &lt;- runif(1000000) mean(gIndicatriz(sampleX,sampleY))*4 ## [1] 3.141924 3.1 Hypothesis Testing A statistical hypothesis is some conjecture about the distribution of one or more random variables. For each hypothesis designated by null hypothesis and denoted by \\(H0\\), there is always an alternative hypothesis denoted by \\(H1\\). We start the test by believing that \\(H0\\) is true, and during the test we can discard that hypothesis only if the data points there. Moreover, we can see these hypothesis testing as: A statistical hypothesis is some statement about the parameters of one or more populations (parametric tests) or about the distribution of the population (non-parametric tests). The goal of a test is to use the information of a data sample to decide (reject or no reject) about a conjecture over unknown aspects of a given population. 3.1.1 Types of error while infering through hypothesis testing There are always some risk associated to statistical inference: *** Type 1 error ***: reject \\(H0\\) when \\(H0\\) is true (rejecting error, aka False Negative in ML nomenclature) *** Type 2 error ***: accept \\(H0\\) when \\(H0\\) is false (no rejecting error, aka False Positive in ML nomenclature) 3.1.2 Defining \\(\\alpha\\) to reduce a type of error \\[ \\alpha = P(Type1Err) = P(Rejecting H0 | H0 is true) \\] So, we define \\(\\alpha\\) as being the probability that we want for the Type 1 error - or how much are we willing to be prone to this type of error. Therefone, \\(\\alpha\\) is called significance level of the test (a test that is very prone to errors is not very significant, right?) In general, we assign a very small value to the probability of type I error (0.05 ou 0.01). On the other end of the error spectrum, we define \\(\\beta\\) as \\[ \\beta = P(Type2Err) = P(Accepting H0 | H0 is false) \\] where \\(1 - \\beta\\) is called power of the test. The insight here is that the lower the \\(\\beta\\), the more “power” this test have. 3.1.3 Procedure to make a test using \\(p-value\\) 3.1.3.1 Wait, what is p-value? (WIP) 3.1.4 Estimating test stats The hypothesis being tested is the following: We have a sample (the variable popSample below) of independent observations from a random variable that we know follows an exponencial distribution, with unknown parameter \\(\\lambda\\). We want to test if \\(\\lambda = 3\\). popSample &lt;- c(0.2,1.2,2.9,1.2,0.1,0.1,0.4,0.1,0.7,0.1,0.9,0.3,0.6,0.1,0.2,0.1,0.4,0.1,0.3,1.4) lambdaEstimator &lt;- function(sample){ 1/mean(sample) } parameter &lt;- 3 testStatsEstimator &lt;- function(sample,hypothesisLambda, estimatedLambda){ sampleMean &lt;- mean(sample) sampleLength &lt;- length(sample) return( ( 1/((sampleMean*hypothesisLambda)^sampleLength)) * (exp( sampleLength* ( hypothesisLambda*sampleMean -1) ) ) ) } tobs &lt;- testStatsEstimator(popSample,parameter,lambdaEstimator(popSample)) Here, we will do the following 1000 times: we get a random sample from an exponential with \\(\\lambda\\) = 3 we obtain the estimated test statistic for this sample By the end of this process, we will get 1000 values that represente possible values of the Test Statistic Function empiricDistTestStats &lt;- sapply(1:1000,function(idx){ sampleTest &lt;- rexp(length(popSample),parameter) testStatsEstimator(sampleTest,parameter,lambdaEstimator(sampleTest)) }) empiricDistTestStats &lt;- c(empiricDistTestStats,tobs) empiricDistTestStats.df &lt;- as.data.frame(empiricDistTestStats) names(empiricDistTestStats.df) &lt;- c(&quot;values&quot;) empiricFrequency &lt;- empiricDistTestStats.df %&gt;% dplyr::group_by(values) %&gt;% dplyr::summarise(n=n()) p_value_estimated &lt;- sum(empiricFrequency[empiricFrequency$values &gt;= tobs,]$n)/sum(empiricFrequency$n) a &lt;- list( text = paste0(&quot;P value estimated: &quot; , round(p_value_estimated,5)), x = tobs, y = 0.3, xref = &quot;x&quot;, yref = &quot;y&quot;, ax = 50 ) plotly::plot_ly( x = empiricDistTestStats , type=&quot;histogram&quot; , histnorm = &quot;probability&quot; , name = &quot;Empiric Frequency&quot;) %&gt;% plotly::add_segments( x = tobs, xend = tobs, y = 0, yend = 0.3, name = &quot;T obs&quot; ) %&gt;% plotly::layout(annotations=a) "],
["deliverables.html", "4 Deliverables", " 4 Deliverables "],
["deliveable-1.html", "5 Deliveable 1 5.1 Exercise 1 5.2 Exercise 2", " 5 Deliveable 1 5.1 Exercise 1 Consider the continuous random variable \\(X\\) with pdf: \\[ f(x) = \\left\\{ \\begin{array}{ll} \\frac{4}{3}(x^3 + x) \\quad \\qquad 0 &lt; x &lt; 1\\\\ 0, \\qquad \\qquad \\qquad\\text{for all others } x \\text{ values}\\\\ \\end{array} \\right. \\] Now consider the random variable \\(Y = g(X)\\), where \\(g(x) = log(x^2 + 4)\\). Estimate \\(P(1.3 &lt; Y &lt; 1.5)\\) using the Monte Carlo Method, as well as the estimator standard deviation. \\[ P(1.3 &lt; Y &lt; 1.5) \\quad = \\quad P(1.3 &lt; g(x) &lt; 1.5) \\quad = \\quad P(1.3 &lt; log(x^2 + 4) &lt; 1.5) \\quad \\] Given that \\(x\\) only present values between \\(0 &lt; x &lt; 1\\), that imples: the minimun value of \\(log(x^2 + 4)\\) is \\(log(4)\\) the maximum value of \\(log(x^2 + 4)\\) is \\(log(5)\\) Therefore, we know that: \\[ P(1.3 &lt; log(x^2 + 4) &lt; log(4)) = 0 \\] With this taken into consideration, the probability that we want to calculate is: \\[ P(log(4) &lt; log(x^2 + 4) &lt; 1.5) \\] Which we can know expand into: \\[ P(log(4) &lt; log(x^2 + 4) &lt; 1.5) \\quad = \\quad P(4 &lt; x^2 + 4 &lt; e^{1.5}) \\quad = \\quad P(0 &lt; x^2 &lt; e^{1.5}-4) \\quad = \\quad P(0 &lt; x &lt; \\sqrt{e^{1.5}-4}) \\] So, we now know that the probability we want to calculate can be obtain by the following integral: \\[\\begin{equation} \\int_{0}^{\\sqrt{e^{1.5}-4}} \\frac{4}{3}(x^3 + x) dx \\tag{5.1} \\end{equation}\\] mc &lt;- function(t){ k &lt;- sqrt(exp(1.5)-4) return ( (4/3) * ((k*t)^3 + k*t) *k ) } #t follows an uniform sample &lt;- runif(100000) pEst &lt;- mean(mc(sample)) varEstimator &lt;- (1/(length(sample)^2))*sum((mc(sample)-pEst)^2) df &lt;- data.frame( probEstimated = pEst, varianceMC = varEstimator ) knitr::kable(df, format = knitr:::pandoc_to()) probEstimated varianceMC 0.397763 7e-07 5.2 Exercise 2 5.2.1 2.1 5.2.2 2.2 lambda &lt;- 0.5 samples &lt;- runif(1000) inverseExp &lt;- function(u, lambda){ -(1/lambda)*log(1-u) } values &lt;- inverseExp(samples, lambda) hist(values, breaks=100, freq = F) g &lt;- function(x){ exp(sqrt(x))*(2/(sqrt(2*pi)))*x^(-1/2) } X &lt;- runif(10000) Y &lt;- runif(10000) EX &lt;- mean(g(inverseExp(X, lambda))) EY &lt;- mean(g(inverseExp(Y, lambda))) "]
]
